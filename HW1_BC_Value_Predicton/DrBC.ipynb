{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLG:hw1_DrBC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM0CFqGD5vnu0WhKWC/6G2E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emschenn/mlg_hw1/blob/master/DrBC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOI2u2B5V4T1",
        "colab_type": "code",
        "outputId": "8f8fee6e-4bcd-46f8-f9a8-58460fedb21b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
        "!pip install torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
        "!pip install torch-cluster==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
        "!pip install torch-spline-conv==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
        "!pip install torch-geometric"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
            "Collecting torch-scatter==latest+cu101\n",
            "\u001b[?25l  Downloading https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.4.0/torch_scatter-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (10.6MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6MB 344kB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.4\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
            "Collecting torch-sparse==latest+cu101\n",
            "\u001b[?25l  Downloading https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.4.0/torch_sparse-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (15.2MB)\n",
            "\u001b[K     |████████████████████████████████| 15.2MB 1.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-sparse==latest+cu101) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-sparse==latest+cu101) (1.18.2)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.1\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
            "Collecting torch-cluster==latest+cu101\n",
            "\u001b[?25l  Downloading https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.4.0/torch_cluster-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (14.5MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5MB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-cluster==latest+cu101) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-cluster==latest+cu101) (1.18.2)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.5.3\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
            "Collecting torch-spline-conv==latest+cu101\n",
            "\u001b[?25l  Downloading https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.4.0/torch_spline_conv-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (5.1MB)\n",
            "\u001b[K     |████████████████████████████████| 5.1MB 477kB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.0\n",
            "Collecting torch-geometric\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/35/8a65fc0b685d916f5f70199d6ad6f19bb002dc3a547a3fe5b68d60047f3b/torch_geometric-1.4.3.tar.gz (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.18.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.16.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.47.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.21.0)\n",
            "Collecting plyfile\n",
            "  Downloading https://files.pythonhosted.org/packages/93/c8/cf47848cd4d661850e4a8e7f0fc4f7298515e06d0da7255ed08e5312d4aa/plyfile-0.7.2-py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.25.3)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/fe/630bacb652680f6d481b9febbb3e2c3869194a1a5fc3401a4a41195a2f8f/rdflib-4.2.2-py3-none-any.whl (344kB)\n",
            "\u001b[K     |████████████████████████████████| 348kB 11.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.10.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch-geometric) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch-geometric) (0.14.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->torch-geometric) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->torch-geometric) (2.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->torch-geometric) (7.0.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->torch-geometric) (3.2.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (46.0.0)\n",
            "Requirement already satisfied: llvmlite>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (0.31.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (2.4.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->torch-geometric) (1.12.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->torch-geometric) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->torch-geometric) (0.10.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.4.3-cp36-none-any.whl size=234873 sha256=2a1d81ad965751a0a26417435f08e317a44bc818c9604ff9af44232c80136d9f\n",
            "  Stored in directory: /root/.cache/pip/wheels/e2/c1/09/8693feee3f97e440d68b09abfca8b4c1e97150ace350b5003f\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: plyfile, isodate, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.0 plyfile-0.7.2 rdflib-4.2.2 torch-geometric-1.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L2aR86_BBrc",
        "colab_type": "code",
        "outputId": "04d995b7-ae52-4988-d8e8-af16c327d153",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# prepare model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import add_self_loops, degree\n",
        "\n",
        "class GCNConv(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCNConv, self).__init__(aggr='add')  # \"Add\" aggregation.\n",
        "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # x has shape [N, in_channels]\n",
        "        # edge_index has shape [2, E]\n",
        "\n",
        "        # Step 1: Add self-loops to the adjacency matrix.\n",
        "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
        "        # Step 2: Linearly transform node feature matrix.\n",
        "        x = self.lin(x)\n",
        "        # Step 3: Compute normalization\n",
        "        row, col = edge_index\n",
        "        deg = degree(row, x.size(0), dtype=x.dtype)\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "        # Step 4-6: Start propagating messages.\n",
        "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x, norm=norm)\n",
        "\n",
        "    def message(self, x_j, norm):\n",
        "        # x_j has shape [E, out_channels]\n",
        "        # Step 4: Normalize node features.\n",
        "        return norm.view(-1, 1) * x_j\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        # aggr_out has shape [N, out_channels]\n",
        "        # Step 6: Return new node embeddings.\n",
        "        return aggr_out\n",
        "\n",
        "class DrBC(nn.Module):\n",
        "    def __init__(self,):\n",
        "        super(DrBC, self).__init__()\n",
        "        # Encoder\n",
        "        self.fc1 = nn.Linear(3, 128)\n",
        "        self.relu = nn.LeakyReLU()\n",
        "\n",
        "        self.gcn1 = GCNConv(128, 128)\n",
        "        self.gru1 = nn.GRU(128, 128)\n",
        "\n",
        "        self.gcn2 = GCNConv(128, 128)\n",
        "        self.gru2 = nn.GRU(128, 128)\n",
        "\n",
        "        self.gcn3 = GCNConv(128, 128)\n",
        "        self.gru3 = nn.GRU(128, 128)\n",
        "\n",
        "        self.gcn4 = GCNConv(128, 128)\n",
        "        self.gru4 = nn.GRU(128, 128)\n",
        "\n",
        "        self.gcn5 = GCNConv(128, 128)\n",
        "        self.gru5 = nn.GRU(128, 128)\n",
        "\n",
        "        # Decoder\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.relu2 = nn.LeakyReLU()\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)        \n",
        "        x_n = self.gcn1(x, edge_index)\n",
        "        x1, _ = self.gru1(x_n.view(1, *x_n.shape), x.view(1, *x.shape))\n",
        "        x_n = self.gcn2(x1[0], edge_index)\n",
        "        x2, _ = self.gru2(x_n.view(1, *x_n.shape), x1)\n",
        "        x_n = self.gcn3(x2[0], edge_index)\n",
        "        x3, _ = self.gru3(x_n.view(1, *x_n.shape), x2)\n",
        "        x_n = self.gcn4(x3[0], edge_index)\n",
        "        x4, _ = self.gru4(x_n.view(1, *x_n.shape), x3)\n",
        "        x_n = self.gcn5(x4[0], edge_index)\n",
        "        x5, _ = self.gru5(x_n.view(1, *x_n.shape), x4)\n",
        "        \n",
        "        # max\n",
        "        l = [x1[0],x2[0],x3[0],x4[0],x5[0]]\n",
        "        l = torch.stack(l)\n",
        "        x = torch.max(l, dim=0).values\n",
        "        # l = torch.tensor(l) \n",
        "\n",
        "        # decoder\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = DrBC()\n",
        "x = torch.tensor([[2, 1, 1],[2, 1, 1],[2, 1, 1],[2, 1, 1]],dtype=torch.float)\n",
        "    \n",
        "edge_index = torch.tensor([[0,1,2],\n",
        "                            [1,2,3]],dtype=torch.long)\n",
        "print(model(x, edge_index))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.0129],\n",
            "        [-0.0143],\n",
            "        [-0.0148],\n",
            "        [-0.0191]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coqKzFtgL6gb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare data\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import random \n",
        "import math\n",
        "\n",
        "class Graph():\n",
        "  def __init__(self,batch_size):\n",
        "    self.graph_list=[]\n",
        "    for x in range(batch_size):\n",
        "      g = nx.powerlaw_cluster_graph(n=random.randint(150,200) , m=4, p=0.05, seed=None)\n",
        "      self.graph_list.append(g)\n",
        "\n",
        "  def get_deg_list(self):\n",
        "    deg_list = []\n",
        "    for g in self.graph_list:\n",
        "      for x in range(g.number_of_nodes()):\n",
        "        deg_list.append([g.degree[x],1,1])\n",
        "    return torch.Tensor(deg_list).cuda()\n",
        "\n",
        "  def get_edge_index(self):\n",
        "    s_list,t_list,en = [],[],0\n",
        "    for g in self.graph_list:\n",
        "      for e in g.edges():\n",
        "        s,t = e\n",
        "        s_list.append(s+en)\n",
        "        t_list.append(t+en)\n",
        "      en += g.number_of_nodes()\n",
        "    edge_index=[s_list+t_list,t_list+s_list]\n",
        "    return torch.tensor(edge_index,dtype=torch.long).cuda()\n",
        "\n",
        "  def get_bc_value(self):\n",
        "    bc_value = []\n",
        "    for g in self.graph_list:\n",
        "      bc_value += list(nx.betweenness_centrality(g).values())\n",
        "    for i, x in enumerate(bc_value):\n",
        "      bc_value[i] = math.log(x+1e-8)\n",
        "    return torch.Tensor(bc_value).cuda()\n",
        "\n",
        "  def get_pair_index(self):\n",
        "    n_list1,n_list2,pair_index,en = [],[],[],0\n",
        "    for g in self.graph_list:\n",
        "      for x in range(g.number_of_nodes()):\n",
        "        n_list1 += [en+x,en+x,en+x,en+x,en+x]\n",
        "        n_list2 += [en+x,en+x,en+x,en+x,en+x]\n",
        "      random.shuffle(n_list1)\n",
        "      random.shuffle(n_list2)\n",
        "      for i,j in zip(n_list1,n_list2):\n",
        "        pair_index.append([i,j])\n",
        "      n_list1,n_list2=[],[]\n",
        "    return torch.tensor(pair_index, dtype=torch.long).cuda()\n",
        "\n",
        "\"\"\"\n",
        "g = Graph(16)\n",
        "print(g.get_deg_list().shape)\n",
        "print(g.get_edge_index().shape)\n",
        "print(g.get_bc_value().shape)\n",
        "print(g.get_pair_index())\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9Q3f1fSW8ir",
        "colab_type": "code",
        "outputId": "3bc31e2e-a126-4201-d4ea-4a66453c1eae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# start training\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "iteration = 10000\n",
        "\n",
        "def train():\n",
        "  model = DrBC()\n",
        "  model = model.cuda()\n",
        "  optimizer = Adam(params=model.parameters(), lr=0.0001)\n",
        "  g = Graph(16)\n",
        "  for iter in range(iteration):\n",
        "    if iter % 500 == 0:\n",
        "      g = Graph(16)\n",
        "      bc = g.get_bc_value()\n",
        "    outs = model(g.get_deg_list(),g.get_edge_index())\n",
        "    pair = g.get_pair_index()\n",
        "    pred = outs[pair[:, 0]] - outs[pair[:, 1]]\n",
        "    gt = torch.sigmoid((bc[pair[:, 0]] - bc[pair[:, 1]]))\n",
        "    gt = gt.view(-1, 1)\n",
        "    loss = F.binary_cross_entropy_with_logits(pred, gt, reduction=\"sum\")\n",
        "    if iter % 1000 == 0:\n",
        "      print(outs[:10])\n",
        "      print(bc[:10])\n",
        "      print(\"[{}/{}] Loss:{:.4f}\".format(iter, iteration, loss.item()))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  torch.save(model.state_dict(), \"./weight.pth\")\n",
        "  return model\n",
        "\n",
        "model = train()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.8163],\n",
            "        [-2.5718],\n",
            "        [-1.9354],\n",
            "        [-1.8641],\n",
            "        [-3.0595],\n",
            "        [-2.9277],\n",
            "        [-1.0913],\n",
            "        [-1.6515],\n",
            "        [-1.5123],\n",
            "        [-1.0283]], device='cuda:0', grad_fn=<SliceBackward>)\n",
            "tensor([-4.1982, -2.2416, -2.7747, -2.7574, -1.9128, -1.9439, -3.6302, -2.9775,\n",
            "        -2.9536, -3.6095], device='cuda:0')\n",
            "[0/10000] Loss:13153.6133\n",
            "tensor([[12.2463],\n",
            "        [ 9.7867],\n",
            "        [ 8.6882],\n",
            "        [ 8.3512],\n",
            "        [13.7626],\n",
            "        [10.5637],\n",
            "        [12.5210],\n",
            "        [ 9.3119],\n",
            "        [11.4221],\n",
            "        [10.4092]], device='cuda:0', grad_fn=<SliceBackward>)\n",
            "tensor([-2.0726, -3.3914, -3.8651, -4.1789, -1.5930, -2.8149, -2.1324, -3.5565,\n",
            "        -2.6275, -3.1112], device='cuda:0')\n",
            "[1000/10000] Loss:6970.8682\n",
            "tensor([[ 5.7578],\n",
            "        [ 7.2877],\n",
            "        [12.0071],\n",
            "        [ 8.0168],\n",
            "        [11.5579],\n",
            "        [11.5579],\n",
            "        [12.0071],\n",
            "        [ 8.0168],\n",
            "        [ 6.1940],\n",
            "        [ 6.1940]], device='cuda:0', grad_fn=<SliceBackward>)\n",
            "tensor([-4.2890, -3.2381, -1.8223, -3.0882, -2.0288, -2.0872, -1.9106, -3.2713,\n",
            "        -4.0566, -4.3347], device='cuda:0')\n",
            "[2000/10000] Loss:7442.2490\n",
            "tensor([[6.2938],\n",
            "        [1.8217],\n",
            "        [3.5666],\n",
            "        [5.3301],\n",
            "        [5.4889],\n",
            "        [5.2507],\n",
            "        [5.4889],\n",
            "        [3.3544],\n",
            "        [5.0125],\n",
            "        [5.3301]], device='cuda:0', grad_fn=<SliceBackward>)\n",
            "tensor([-2.1560, -5.0704, -3.8792, -2.8185, -2.6488, -2.7575, -2.7201, -3.9306,\n",
            "        -2.9315, -2.6768], device='cuda:0')\n",
            "[3000/10000] Loss:7371.9893\n",
            "tensor([[7.6080],\n",
            "        [7.2494],\n",
            "        [6.6041],\n",
            "        [7.3928],\n",
            "        [8.8269],\n",
            "        [8.0382],\n",
            "        [6.8192],\n",
            "        [6.5324],\n",
            "        [7.4646],\n",
            "        [3.5827]], device='cuda:0', grad_fn=<SliceBackward>)\n",
            "tensor([-2.3643, -2.7720, -3.7498, -2.8086, -1.7360, -2.1547, -3.5698, -3.4936,\n",
            "        -2.6732, -6.5314], device='cuda:0')\n",
            "[4000/10000] Loss:6690.8960\n",
            "tensor([[26.6653],\n",
            "        [31.2312],\n",
            "        [34.3017],\n",
            "        [33.6437],\n",
            "        [36.4949],\n",
            "        [36.2755],\n",
            "        [31.4505],\n",
            "        [34.7403],\n",
            "        [32.1085],\n",
            "        [33.8630]], device='cuda:0', grad_fn=<SliceBackward>)\n",
            "tensor([-7.6280, -3.5549, -2.5848, -2.7938, -1.9911, -2.1080, -3.3619, -2.4078,\n",
            "        -3.3442, -2.5921], device='cuda:0')\n",
            "[5000/10000] Loss:7224.9189\n",
            "tensor([[25.0891],\n",
            "        [27.4372],\n",
            "        [26.0115],\n",
            "        [25.4245],\n",
            "        [26.0115],\n",
            "        [25.2568],\n",
            "        [24.7239],\n",
            "        [25.2568],\n",
            "        [24.0520],\n",
            "        [24.2019]], device='cuda:0', grad_fn=<SliceBackward>)\n",
            "tensor([-2.9463, -1.6025, -2.2966, -2.5540, -2.3767, -2.6348, -3.2599, -2.7927,\n",
            "        -4.2770, -4.0522], device='cuda:0')\n",
            "[6000/10000] Loss:7364.6348\n",
            "tensor([[38.2159],\n",
            "        [36.7839],\n",
            "        [39.2657],\n",
            "        [36.3528],\n",
            "        [41.2528],\n",
            "        [39.7233],\n",
            "        [38.9605],\n",
            "        [39.2657],\n",
            "        [40.0284],\n",
            "        [37.8615]], device='cuda:0', grad_fn=<SliceBackward>)\n",
            "tensor([-3.2641, -4.3575, -2.5769, -4.1422, -1.9546, -2.3545, -2.8240, -2.5595,\n",
            "        -2.2693, -3.3916], device='cuda:0')\n",
            "[7000/10000] Loss:7079.6582\n",
            "tensor([[18.4154],\n",
            "        [19.0935],\n",
            "        [17.4661],\n",
            "        [19.8691],\n",
            "        [18.2798],\n",
            "        [18.4154],\n",
            "        [16.3811],\n",
            "        [16.3811],\n",
            "        [18.5510],\n",
            "        [17.4661]], device='cuda:0', grad_fn=<SliceBackward>)\n",
            "tensor([-2.8024, -2.2392, -2.9136, -2.0264, -2.7905, -2.5040, -3.8268, -4.0266,\n",
            "        -2.5545, -2.9722], device='cuda:0')\n",
            "[8000/10000] Loss:6544.5596\n",
            "tensor([[21.7119],\n",
            "        [21.9098],\n",
            "        [22.2067],\n",
            "        [21.0417],\n",
            "        [24.6545],\n",
            "        [25.3598],\n",
            "        [24.6545],\n",
            "        [21.3869],\n",
            "        [21.9098],\n",
            "        [22.0087]], device='cuda:0', grad_fn=<SliceBackward>)\n",
            "tensor([-3.6931, -3.5392, -3.3572, -4.3883, -2.0866, -1.9126, -2.0232, -3.8652,\n",
            "        -3.2907, -3.0192], device='cuda:0')\n",
            "[9000/10000] Loss:6979.3330\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ylhgWVw4wbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read file\n",
        "import urllib.request  \n",
        "\n",
        "class readFile():\n",
        "  def __init__(self,file):\n",
        "    if file == 'y':\n",
        "      url1 = 'https://raw.githubusercontent.com/emschenn/mlg_hw1/master/hw1_data/youtube/com-youtube.txt' \n",
        "      url2 = 'https://raw.githubusercontent.com/emschenn/mlg_hw1/master/hw1_data/youtube/com-youtube_score.txt' \n",
        "    else:\n",
        "      url1 = 'https://raw.githubusercontent.com/emschenn/mlg_hw1/master/hw1_data/Synthetic/5000/' + file + '.txt'\n",
        "      url2 = 'https://raw.githubusercontent.com/emschenn/mlg_hw1/master/hw1_data/Synthetic/5000/' + file + '_score.txt'\n",
        "    self.bc_value,s_list,t_list,self.deg_list,n = [],[],[],[],0\n",
        "    for line in urllib.request.urlopen(url2):\n",
        "      _,v = line.decode('utf-8').split()\n",
        "      self.bc_value.append([n,math.log(float(v)+1e-8)])\n",
        "      n += 1\n",
        "    for x in range(len(self.bc_value)):\n",
        "      self.deg_list.append([0,1,1])\n",
        "    for line in urllib.request.urlopen(url1):\n",
        "      s,t = line.decode('utf-8').split()\n",
        "      s,t = int(s),int(t)\n",
        "      s_list.append(s)\n",
        "      t_list.append(t)\n",
        "      self.deg_list[s][0]+=1\n",
        "      self.deg_list[t][0]+=1\n",
        "    self.edge_index=[s_list+t_list,t_list+s_list]\n",
        "\n",
        "  def get_deg_list(self):\n",
        "    # print(self.deg_list)\n",
        "    return torch.Tensor(self.deg_list).cuda()\n",
        "\n",
        "  def get_edge_index(self):\n",
        "    # print(self.edge_index)\n",
        "    return torch.tensor(self.edge_index,dtype=torch.long).cuda()\n",
        "\n",
        "  def get_bc_value(self):\n",
        "    # print(self.bc_value)\n",
        "    return self.bc_value\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg48odOXl7D-",
        "colab_type": "code",
        "outputId": "d63223ff-32bf-4f50-af57-204bba19d91d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# Evaluation\n",
        "f = readFile('y')\n",
        "model = model.cpu()\n",
        "t = f.get_deg_list().cpu()\n",
        "t1 = f.get_edge_index().cpu()\n",
        "with torch.no_grad():\n",
        "  outs = model(t,t1)\n",
        "\n",
        "# Top-N % accuracy\n",
        "def takeSecond(elem):\n",
        "    return elem[1]\n",
        "\n",
        "def topN_accuracy(file,outs,n):\n",
        "  predict_value,bc_value = [],[]\n",
        "  for i,j in enumerate(outs.tolist()):\n",
        "    predict_value.append([i,*j])\n",
        "  bc_value = f.get_bc_value()\n",
        "  bc_value.sort(key = takeSecond,reverse = True)\n",
        "  predict_value.sort(key = takeSecond,reverse = True)\n",
        "  p,t = [],[]\n",
        "  for x in range(int(len(predict_value)*n/100)):\n",
        "    p.append(predict_value[x][0])\n",
        "    t.append(bc_value[x][0])\n",
        "  # print(t)\n",
        "  # print(p)\n",
        "  return(len(set(t)&set(p)) / len(p))\n",
        "\n",
        "print(topN_accuracy(f,outs,n=1))\n",
        "print(topN_accuracy(f,outs,n=5))\n",
        "print(topN_accuracy(f,outs,n=10))\n",
        "\n",
        "# Kendall tau\n",
        "import scipy.stats as stats\n",
        "def kendall_tau(file,outs):\n",
        "  predict_value,bc_value = [],[]\n",
        "  for i,j in enumerate(outs.tolist()):\n",
        "    predict_value.append(*j)\n",
        "  for i in file.get_bc_value():\n",
        "    bc_value.append(i[1])\n",
        "  # print(predict_value)\n",
        "  # print(bc_value)\n",
        "  tau, _ = stats.kendalltau(predict_value, bc_value)\n",
        "  return(tau)\n",
        "\n",
        "print(kendall_tau(f,outs))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6323581247796969\n",
            "0.6157831665021852\n",
            "0.6388196212848822\n",
            "0.3689769103872301\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bsts2hgzNLdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}